{"cells":[{"metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## # Introduction\n<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"},{"metadata":{"dc":{"key":"3"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"### Task 1: Import libraries\nimport requests                  # To get objects from the web\nimport nltk                      # To manipulate text data\nfrom bs4 import BeautifulSoup    # To manipulate HTML code\nfrom collections import Counter  # To count words\n\n### Task 2: Get HTML\n# Request HTML response from website\nr = requests.get(\"https://www.gutenberg.org/files/16/16-h/16-h.htm\")\n\n# Set the response encoding to utf-8\nr.encoding = 'utf-8'\n\n# Get HTML code from response\nhtml = r.text\n\n### Task 3: Get text\n# Convert to Unicode\nsoup = BeautifulSoup(html)\n\n# Extract text\ntext = soup.text\n\n### Task 4: Get words\n# Create tokenizer\ntokenizer = nltk.tokenize.RegexpTokenizer(\"\\w+\")\n\n# Tokenize text\ntokens = tokenizer.tokenize(text)\n\n### Task 5: Lowercase\n# Lowercase tokens\nwords = [token.lower() for token in tokens]\n\n### Task 6: Load stopwords\n### Task 6: Define stopwords directly\nstop_words = [\n    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\n    \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n    'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n    'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n    'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n    'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n    'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n    'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n    'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',\n    'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',\n    'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now',\n    'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n    'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven',\n    \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn',\n    \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren',\n    \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n]\n\n### Task 7: Remove stopwords\n# Remove stopwords from tokens list\nwords_clean = [word for word in words if word not in stop_words]\n\n### Task 8: Count words\n# Get count dictionary\ncount = Counter(words_clean)\n\n# Get top 10 most common words\ntop_ten = count.most_common(10)\n\n### Task 9: Declare protagonists\nprotagonists = [\"hook\", \"john\", \"peter\", \"wendy\"]","execution_count":2,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}